{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e8bf64-ce7c-4187-8300-d07056b99743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 442 scored movie files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating newprompt results: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 442/442 [00:00<00:00, 1451.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ‰ Aggregation complete! CSVs saved into: /Users/cedricroetheli/Desktop/processed_subs/aggregated_newprompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Paths ===\n",
    "base_path = Path.home() / \"Desktop\" / \"processed_subs\"\n",
    "scored_dir = base_path / \"scored_prompts_claude_new\"\n",
    "output_dir = base_path / \"aggregated_newprompt\"\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Helper functions ===\n",
    "def extract_year_and_title(filename):\n",
    "    \"\"\"Extract year and movie title from filename like '2017_Logan'.\"\"\"\n",
    "    try:\n",
    "        parts = filename.split(\"_\", 1)\n",
    "        year = int(parts[0])\n",
    "        title = parts[1].replace(\"_\", \" \")\n",
    "        return year, title\n",
    "    except Exception:\n",
    "        return None, filename\n",
    "\n",
    "def load_scored_file(filepath):\n",
    "    \"\"\"Load one movie's scored chunk results.\"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def compute_unweighted(df):\n",
    "    \"\"\"Compute simple averages without weighting.\"\"\"\n",
    "    return {\n",
    "        \"universalism\": df[\"universalism_score\"].mean(),\n",
    "        \"egalitarianism\": df[\"egalitarianism_score\"].mean(),\n",
    "        \"progress\": df[\"progress_score\"].mean(),\n",
    "    }\n",
    "\n",
    "def compute_weighted(df):\n",
    "    \"\"\"Compute confidence-weighted averages.\"\"\"\n",
    "    def weighted_avg(value_col, conf_col):\n",
    "        if df[conf_col].sum() == 0:\n",
    "            return df[value_col].mean()  # fallback to unweighted\n",
    "        return (df[value_col] * df[conf_col]).sum() / df[conf_col].sum()\n",
    "    \n",
    "    return {\n",
    "        \"universalism\": weighted_avg(\"universalism_score\", \"universalism_confidence\"),\n",
    "        \"egalitarianism\": weighted_avg(\"egalitarianism_score\", \"egalitarianism_confidence\"),\n",
    "        \"progress\": weighted_avg(\"progress_score\", \"progress_confidence\"),\n",
    "    }\n",
    "\n",
    "# === Main aggregation ===\n",
    "unweighted_records = []\n",
    "weighted_records = []\n",
    "\n",
    "scored_files = list(scored_dir.glob(\"*.json\"))\n",
    "print(f\"Found {len(scored_files)} scored movie files.\")\n",
    "\n",
    "for scored_file in tqdm(scored_files, desc=\"Aggregating newprompt results\"):\n",
    "    movie_id = scored_file.stem.replace(\"_scored\", \"\")\n",
    "    year, title = extract_year_and_title(movie_id)\n",
    "\n",
    "    try:\n",
    "        data = load_scored_file(scored_file)\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        unweighted_scores = compute_unweighted(df)\n",
    "        weighted_scores = compute_weighted(df)\n",
    "\n",
    "        unweighted_records.append({\n",
    "            \"year\": year,\n",
    "            \"title\": title,\n",
    "            **unweighted_scores\n",
    "        })\n",
    "\n",
    "        weighted_records.append({\n",
    "            \"year\": year,\n",
    "            \"title\": title,\n",
    "            **weighted_scores\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error processing {scored_file.name}: {e}\")\n",
    "\n",
    "# === Create DataFrames ===\n",
    "df_unweighted = pd.DataFrame(unweighted_records)\n",
    "df_weighted = pd.DataFrame(weighted_records)\n",
    "\n",
    "# Save per movie\n",
    "df_unweighted.to_csv(output_dir / \"newprompt_unweighted_movie.csv\", index=False)\n",
    "df_weighted.to_csv(output_dir / \"newprompt_weighted_movie.csv\", index=False)\n",
    "\n",
    "# === Aggregate per year ===\n",
    "df_unweighted_year = (\n",
    "    df_unweighted\n",
    "    .groupby(\"year\")[[\"universalism\", \"egalitarianism\", \"progress\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_weighted_year = (\n",
    "    df_weighted\n",
    "    .groupby(\"year\")[[\"universalism\", \"egalitarianism\", \"progress\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_unweighted_year.to_csv(output_dir / \"newprompt_unweighted_year.csv\", index=False)\n",
    "df_weighted_year.to_csv(output_dir / \"newprompt_weighted_year.csv\", index=False)\n",
    "\n",
    "print(\"\\nðŸŽ‰ Aggregation complete! CSVs saved into:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa3db44-505f-4043-af89-fd361f0af84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 441 scored files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating v2 results: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 441/441 [00:00<00:00, 5361.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Aggregated results saved to:\n",
      "/Users/cedricroetheli/Desktop/processed_subs/heroes_and_moral_v2_movie.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Paths ===\n",
    "base_path = Path.home() / \"Desktop\" / \"processed_subs\"\n",
    "scored_dir = base_path / \"scored_heroes_and_moral_v2\"\n",
    "output_csv = base_path / \"heroes_and_moral_v2_movie.csv\"\n",
    "\n",
    "# === Helper to extract year and title ===\n",
    "def parse_filename(filename):\n",
    "    try:\n",
    "        year, title = filename.split(\"_\", 1)\n",
    "        return int(year), title.replace(\"_\", \" \")\n",
    "    except Exception:\n",
    "        return None, filename\n",
    "\n",
    "# === Load and aggregate ===\n",
    "records = []\n",
    "\n",
    "files = list(scored_dir.glob(\"*.json\"))\n",
    "print(f\"Found {len(files)} scored files.\")\n",
    "\n",
    "for file in tqdm(files, desc=\"Aggregating v2 results\"):\n",
    "    try:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed to load {file.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    year, title = parse_filename(file.stem.replace(\"_heroes_and_moral_v2_scored\", \"\"))\n",
    "\n",
    "    moral = data.get(\"moral_intervention_vs_isolation\", [None, None])\n",
    "    hero = data.get(\"hero\", {})\n",
    "    villain = data.get(\"villain\", {})\n",
    "\n",
    "    records.append({\n",
    "        \"year\": year,\n",
    "        \"title\": title,\n",
    "        \"moral_score\": moral[0],\n",
    "        \"moral_confidence\": moral[1],\n",
    "        \"hero_name\": hero.get(\"name\", \"UNKNOWN\"),\n",
    "        \"hero_entity_type\": hero.get(\"entity_type\", \"UNKNOWN\"),\n",
    "        \"hero_affiliation\": hero.get(\"affiliation\", \"UNKNOWN\"),\n",
    "        \"hero_confidence\": hero.get(\"confidence\", None),\n",
    "        \"villain_name\": villain.get(\"name\", \"UNKNOWN\"),\n",
    "        \"villain_entity_type\": villain.get(\"entity_type\", \"UNKNOWN\"),\n",
    "        \"villain_affiliation\": villain.get(\"affiliation\", \"UNKNOWN\"),\n",
    "        \"villain_confidence\": villain.get(\"confidence\", None),\n",
    "    })\n",
    "\n",
    "# === Save to CSV ===\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"\\nâœ… Aggregated results saved to:\\n{output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706730fb-8d21-4a3b-9d9d-5d9e157b9edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_clean_env_py310)",
   "language": "python",
   "name": "my_clean_env_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
