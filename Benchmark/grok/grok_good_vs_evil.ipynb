{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c33e742-79df-49a5-9688-821351b950a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):   0%|                       | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2006Blood.Diamond chunk 1\n",
      "âœ… Scored: 2006Blood.Diamond chunk 2\n",
      "âœ… Scored: 2006Blood.Diamond chunk 3\n",
      "âœ… Scored: 2006Blood.Diamond chunk 4\n",
      "âœ… Scored: 2006Blood.Diamond chunk 5\n",
      "âœ… Scored: 2006Blood.Diamond chunk 6\n",
      "âœ… Scored: 2006Blood.Diamond chunk 7\n",
      "âœ… Scored: 2006Blood.Diamond chunk 8\n",
      "âœ… Scored: 2006Blood.Diamond chunk 9\n",
      "âœ… Scored: 2006Blood.Diamond chunk 10\n",
      "âœ… Scored: 2006Blood.Diamond chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):   5%|â–Š              | 1/20 [01:00<19:18, 60.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2005The.Constant.Gardener chunk 1\n",
      "âœ… Scored: 2005The.Constant.Gardener chunk 2\n",
      "âœ… Scored: 2005The.Constant.Gardener chunk 3\n",
      "âœ… Scored: 2005The.Constant.Gardener chunk 4\n",
      "âœ… Scored: 2005The.Constant.Gardener chunk 5\n",
      "âœ… Scored: 2005The.Constant.Gardener chunk 6\n",
      "âœ… Scored: 2005The.Constant.Gardener chunk 7\n",
      "âœ… Scored: 2005The.Constant.Gardener chunk 8\n",
      "âœ… Scored: 2005The.Constant.Gardener chunk 9\n",
      "âœ… Scored: 2005The.Constant.Gardener chunk 10\n",
      "âœ… Scored: 2005The.Constant.Gardener chunk 11\n",
      "âœ… Scored: 2005The.Constant.Gardener chunk 12\n",
      "âœ… Scored: 2005The.Constant.Gardener chunk 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  10%|â–ˆâ–Œ             | 2/20 [02:14<20:25, 68.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 1\n",
      "âœ… Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 2\n",
      "âœ… Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 3\n",
      "âœ… Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 4\n",
      "âœ… Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 5\n",
      "âœ… Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  15%|â–ˆâ–ˆâ–Ž            | 3/20 [02:48<14:53, 52.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2009Avatar chunk 1\n",
      "âœ… Scored: 2009Avatar chunk 2\n",
      "âœ… Scored: 2009Avatar chunk 3\n",
      "âœ… Scored: 2009Avatar chunk 4\n",
      "âœ… Scored: 2009Avatar chunk 5\n",
      "âœ… Scored: 2009Avatar chunk 6\n",
      "âœ… Scored: 2009Avatar chunk 7\n",
      "âœ… Scored: 2009Avatar chunk 8\n",
      "âœ… Scored: 2009Avatar chunk 9\n",
      "âœ… Scored: 2009Avatar chunk 10\n",
      "âœ… Scored: 2009Avatar chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  20%|â–ˆâ–ˆâ–ˆ            | 4/20 [03:47<14:45, 55.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2012The.Hunger.Games chunk 1\n",
      "âœ… Scored: 2012The.Hunger.Games chunk 2\n",
      "âœ… Scored: 2012The.Hunger.Games chunk 3\n",
      "âœ… Scored: 2012The.Hunger.Games chunk 4\n",
      "âœ… Scored: 2012The.Hunger.Games chunk 5\n",
      "âœ… Scored: 2012The.Hunger.Games chunk 6\n",
      "âœ… Scored: 2012The.Hunger.Games chunk 7\n",
      "âœ… Scored: 2012The.Hunger.Games chunk 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  25%|â–ˆâ–ˆâ–ˆâ–Š           | 5/20 [04:31<12:47, 51.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 1984Ghostbusters chunk 1\n",
      "âœ… Scored: 1984Ghostbusters chunk 2\n",
      "âœ… Scored: 1984Ghostbusters chunk 3\n",
      "âœ… Scored: 1984Ghostbusters chunk 4\n",
      "âœ… Scored: 1984Ghostbusters chunk 5\n",
      "âœ… Scored: 1984Ghostbusters chunk 6\n",
      "âœ… Scored: 1984Ghostbusters chunk 7\n",
      "âœ… Scored: 1984Ghostbusters chunk 8\n",
      "âœ… Scored: 1984Ghostbusters chunk 9\n",
      "âœ… Scored: 1984Ghostbusters chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 6/20 [05:24<12:07, 51.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 1978Superman chunk 1\n",
      "âœ… Scored: 1978Superman chunk 2\n",
      "âœ… Scored: 1978Superman chunk 3\n",
      "âœ… Scored: 1978Superman chunk 4\n",
      "âœ… Scored: 1978Superman chunk 5\n",
      "âœ… Scored: 1978Superman chunk 6\n",
      "âœ… Scored: 1978Superman chunk 7\n",
      "âœ… Scored: 1978Superman chunk 8\n",
      "âœ… Scored: 1978Superman chunk 9\n",
      "âœ… Scored: 1978Superman chunk 10\n",
      "âœ… Scored: 1978Superman chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 7/20 [06:31<12:18, 56.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2008The.Hurt.Locker chunk 1\n",
      "âœ… Scored: 2008The.Hurt.Locker chunk 2\n",
      "âœ… Scored: 2008The.Hurt.Locker chunk 3\n",
      "âœ… Scored: 2008The.Hurt.Locker chunk 4\n",
      "âœ… Scored: 2008The.Hurt.Locker chunk 5\n",
      "âœ… Scored: 2008The.Hurt.Locker chunk 6\n",
      "âœ… Scored: 2008The.Hurt.Locker chunk 7\n",
      "âœ… Scored: 2008The.Hurt.Locker chunk 8\n",
      "âœ… Scored: 2008The.Hurt.Locker chunk 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 8/20 [07:20<10:52, 54.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 1\n",
      "âœ… Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 2\n",
      "âœ… Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 3\n",
      "âœ… Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 4\n",
      "âœ… Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 5\n",
      "âœ… Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 6\n",
      "âœ… Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 7\n",
      "âœ… Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 8\n",
      "âœ… Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 9\n",
      "âœ… Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 10\n",
      "âœ… Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 11\n",
      "âœ… Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 9/20 [08:24<10:29, 57.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 1\n",
      "âœ… Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 2\n",
      "âœ… Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 3\n",
      "âœ… Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 4\n",
      "âœ… Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 5\n",
      "âœ… Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 6\n",
      "âœ… Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 7\n",
      "âœ… Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 8\n",
      "âœ… Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 9\n",
      "âœ… Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 10/20 [09:18<09:22, 56.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2018Black.Panther chunk 1\n",
      "âœ… Scored: 2018Black.Panther chunk 2\n",
      "âœ… Scored: 2018Black.Panther chunk 3\n",
      "âœ… Scored: 2018Black.Panther chunk 4\n",
      "âœ… Scored: 2018Black.Panther chunk 5\n",
      "âœ… Scored: 2018Black.Panther chunk 6\n",
      "âœ… Scored: 2018Black.Panther chunk 7\n",
      "âœ… Scored: 2018Black.Panther chunk 8\n",
      "âœ… Scored: 2018Black.Panther chunk 9\n",
      "âœ… Scored: 2018Black.Panther chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 11/20 [10:14<08:24, 56.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2021Dont.Look.Up chunk 1\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 2\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 3\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 4\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 5\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 6\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 7\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 8\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 9\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 10\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 11\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 12\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 13\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 14\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 15\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 16\n",
      "âœ… Scored: 2021Dont.Look.Up chunk 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/20 [11:45<08:53, 66.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 1982First.Blood chunk 1\n",
      "âœ… Scored: 1982First.Blood chunk 2\n",
      "âœ… Scored: 1982First.Blood chunk 3\n",
      "âœ… Scored: 1982First.Blood chunk 4\n",
      "âœ… Scored: 1982First.Blood chunk 5\n",
      "âœ… Scored: 1982First.Blood chunk 6\n",
      "âœ… Scored: 1982First.Blood chunk 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 13/20 [12:24<06:48, 58.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2019Joker chunk 1\n",
      "âœ… Scored: 2019Joker chunk 2\n",
      "âœ… Scored: 2019Joker chunk 3\n",
      "âœ… Scored: 2019Joker chunk 4\n",
      "âœ… Scored: 2019Joker chunk 5\n",
      "âœ… Scored: 2019Joker chunk 6\n",
      "âœ… Scored: 2019Joker chunk 7\n",
      "âœ… Scored: 2019Joker chunk 8\n",
      "âœ… Scored: 2019Joker chunk 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/20 [13:24<05:52, 58.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2006Night.at.the.Museum chunk 1\n",
      "âœ… Scored: 2006Night.at.the.Museum chunk 2\n",
      "âœ… Scored: 2006Night.at.the.Museum chunk 3\n",
      "âœ… Scored: 2006Night.at.the.Museum chunk 4\n",
      "âœ… Scored: 2006Night.at.the.Museum chunk 5\n",
      "âœ… Scored: 2006Night.at.the.Museum chunk 6\n",
      "âœ… Scored: 2006Night.at.the.Museum chunk 7\n",
      "âœ… Scored: 2006Night.at.the.Museum chunk 8\n",
      "âœ… Scored: 2006Night.at.the.Museum chunk 9\n",
      "âœ… Scored: 2006Night.at.the.Museum chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15/20 [14:20<04:50, 58.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 1976Rocky.I chunk 1\n",
      "âœ… Scored: 1976Rocky.I chunk 2\n",
      "âœ… Scored: 1976Rocky.I chunk 3\n",
      "âœ… Scored: 1976Rocky.I chunk 4\n",
      "âœ… Scored: 1976Rocky.I chunk 5\n",
      "âœ… Scored: 1976Rocky.I chunk 6\n",
      "âœ… Scored: 1976Rocky.I chunk 7\n",
      "âœ… Scored: 1976Rocky.I chunk 8\n",
      "âœ… Scored: 1976Rocky.I chunk 9\n",
      "âœ… Scored: 1976Rocky.I chunk 10\n",
      "âœ… Scored: 1976Rocky.I chunk 11\n",
      "âœ… Scored: 1976Rocky.I chunk 12\n",
      "âœ… Scored: 1976Rocky.I chunk 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 16/20 [15:34<04:11, 62.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2005V.for.Vendetta chunk 1\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 2\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 3\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 4\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 5\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 6\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 7\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 8\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 9\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 10\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 11\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 12\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 13\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 14\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 15\n",
      "âœ… Scored: 2005V.for.Vendetta chunk 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 17/20 [17:36<04:02, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2017Paddington.2 chunk 1\n",
      "âœ… Scored: 2017Paddington.2 chunk 2\n",
      "âœ… Scored: 2017Paddington.2 chunk 3\n",
      "âœ… Scored: 2017Paddington.2 chunk 4\n",
      "âœ… Scored: 2017Paddington.2 chunk 5\n",
      "âœ… Scored: 2017Paddington.2 chunk 6\n",
      "âœ… Scored: 2017Paddington.2 chunk 7\n",
      "âœ… Scored: 2017Paddington.2 chunk 8\n",
      "âœ… Scored: 2017Paddington.2 chunk 9\n",
      "âœ… Scored: 2017Paddington.2 chunk 10\n",
      "âœ… Scored: 2017Paddington.2 chunk 11\n",
      "âœ… Scored: 2017Paddington.2 chunk 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 18/20 [18:42<02:32, 76.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 1985Back.To.The.Future chunk 1\n",
      "âœ… Scored: 1985Back.To.The.Future chunk 2\n",
      "âœ… Scored: 1985Back.To.The.Future chunk 3\n",
      "âœ… Scored: 1985Back.To.The.Future chunk 4\n",
      "âœ… Scored: 1985Back.To.The.Future chunk 5\n",
      "âœ… Scored: 1985Back.To.The.Future chunk 6\n",
      "âœ… Scored: 1985Back.To.The.Future chunk 7\n",
      "âœ… Scored: 1985Back.To.The.Future chunk 8\n",
      "âœ… Scored: 1985Back.To.The.Future chunk 9\n",
      "âœ… Scored: 1985Back.To.The.Future chunk 10\n",
      "âœ… Scored: 1985Back.To.The.Future chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 19/20 [19:46<01:12, 72.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scored: 2013The.Purge chunk 1\n",
      "âœ… Scored: 2013The.Purge chunk 2\n",
      "âœ… Scored: 2013The.Purge chunk 3\n",
      "âœ… Scored: 2013The.Purge chunk 4\n",
      "âœ… Scored: 2013The.Purge chunk 5\n",
      "âœ… Scored: 2013The.Purge chunk 6\n",
      "âœ… Scored: 2013The.Purge chunk 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring Good vs Evil (Grok): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [20:23<00:00, 61.20s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Grok API setup ===\n",
    "api_key = \"api-key\"\n",
    "api_url = \"https://api.x.ai/v1/chat/completions\"\n",
    "model_name = \"grok-3-mini\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "# === Paths ===\n",
    "base = Path.home() / \"Desktop\" / \"Benchmark\"\n",
    "subs_dir = base / \"json_benchmark\"\n",
    "summaries_dir = base / \"summaries\"\n",
    "output_dir = base / \"scored_good_vs_evil_grok\"\n",
    "prompts_dir = base / \"prompts_good_vs_evil_grok\"\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "prompts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "matches_df = pd.read_csv(base / \"matches_benchmark.csv\")\n",
    "\n",
    "# === Prompt template ===\n",
    "def create_good_vs_evil_prompt(summary, chunk):\n",
    "    return f\"\"\"\n",
    "You are analyzing how a film portrays its central moral conflict based on its plot summary and dialogue.\n",
    "\n",
    "Your task is to classify the filmâ€™s depiction of **Good vs Evil** into one of the following three categories:\n",
    "\n",
    "- **Clear**: There is a strong moral binary. Good and evil are clearly distinguished. One side is righteous, the other is corrupt or villainous.\n",
    "- **Neutral**: The film does not emphasize good vs evil. There may be conflict, but it is not framed in strong moral terms.\n",
    "- **Complicated**: The line between good and evil is blurred. Moral ambiguity is central, and characters or institutions cannot be easily classified as good or evil.\n",
    "\n",
    "Please:\n",
    "1. Choose the best fitting label: \"clear\", \"neutral\", or \"complicated\"\n",
    "2. Give a brief justification (1â€“2 sentences)\n",
    "3. Provide a confidence score between 0.0 and 1.0\n",
    "\n",
    "Return your answer in this exact JSON format:\n",
    "\n",
    "{{\n",
    "  \"good_vs_evil\": \"...\",\n",
    "  \"confidence\": ...,\n",
    "  \"explanation\": \"...\"\n",
    "}}\n",
    "\n",
    "Film Summary:\n",
    "\\\"\\\"\\\"{summary}\\\"\\\"\\\"\n",
    "\n",
    "Dialogue:\n",
    "\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\n",
    "\"\"\".strip()\n",
    "\n",
    "# === API call to Grok ===\n",
    "def call_grok(prompt):\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"temperature\": 0,\n",
    "        \"stream\": False,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a careful film analyst. Always return exactly and only the required JSON.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(api_url, headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code == 429:\n",
    "        print(\"âš ï¸ Rate limit hit. Waiting...\")\n",
    "        time.sleep(60)\n",
    "        return call_grok(prompt)\n",
    "    elif response.status_code != 200:\n",
    "        print(f\"âŒ API Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return json.loads(content)\n",
    "    except Exception:\n",
    "        print(f\"âš ï¸ JSON parsing error:\\n{response.text}\")\n",
    "        return None\n",
    "\n",
    "# === Chunk subtitles ===\n",
    "def chunk_dialogue(subs, chunk_size=5000, overlap=200):\n",
    "    text_blocks = [line.get(\"text\", \"\").strip() for line in subs if line.get(\"text\")]\n",
    "    full_text = \" \".join(text_blocks)\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(full_text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(full_text[start:end])\n",
    "        start = end - overlap\n",
    "    return chunks\n",
    "\n",
    "# === Scoring loop ===\n",
    "for _, row in tqdm(matches_df.iterrows(), total=len(matches_df), desc=\"Scoring Good vs Evil (Grok)\"):\n",
    "    filename = row[\"subtitle_filename\"]\n",
    "    json_path = subs_dir / f\"{filename}.json\"\n",
    "    summary_path = summaries_dir / f\"{filename}.srt_summary.txt\"\n",
    "\n",
    "    if not json_path.exists() or not summary_path.exists():\n",
    "        print(f\"âš ï¸ Missing files for: {filename}\")\n",
    "        continue\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        subs = json.load(f)\n",
    "\n",
    "    with open(summary_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        summary = f.read().strip()\n",
    "\n",
    "    chunks = chunk_dialogue(subs)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        output_path = output_dir / f\"{filename}_chunk{i+1}_good_vs_evil.json\"\n",
    "        prompt_path = prompts_dir / f\"{filename}_chunk{i+1}_good_vs_evil_prompt.txt\"\n",
    "\n",
    "        if output_path.exists():\n",
    "            print(f\"ðŸŸ¡ Already scored: {filename} chunk {i+1}\")\n",
    "            continue\n",
    "\n",
    "        prompt = create_good_vs_evil_prompt(summary, chunk)\n",
    "\n",
    "        with open(prompt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(prompt)\n",
    "\n",
    "        result = call_grok(prompt)\n",
    "        if result:\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(result, f, indent=2)\n",
    "            print(f\"âœ… Scored: {filename} chunk {i+1}\")\n",
    "        else:\n",
    "            print(f\"âŒ Failed: {filename} chunk {i+1}\")\n",
    "\n",
    "        time.sleep(1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5498e351-7583-40cc-87f8-dc1de022b913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved aggregated results to: /Users/cedricroetheli/Desktop/Benchmark/model_good_vs_evil_output_grok.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# === Paths ===\n",
    "base_path = Path.home() / \"Desktop\" / \"Benchmark\"\n",
    "scored_dir = base_path / \"scored_good_vs_evil_grok\"\n",
    "output_csv_path = base_path / \"model_good_vs_evil_output_grok.csv\"\n",
    "\n",
    "# === Aggregate Results ===\n",
    "aggregated_results = []\n",
    "\n",
    "# Group chunk files by movie\n",
    "movie_files = defaultdict(list)\n",
    "for file in scored_dir.glob(\"*_chunk*_good_vs_evil.json\"):\n",
    "    movie_id = file.name.split(\"_chunk\")[0]\n",
    "    movie_files[movie_id].append(file)\n",
    "\n",
    "# Process each movie's chunks\n",
    "for movie_id, files in movie_files.items():\n",
    "    label_counts = Counter()\n",
    "    confidence_sums = defaultdict(float)\n",
    "    confidence_counts = defaultdict(int)\n",
    "    explanations = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                label = data.get(\"good_vs_evil\", \"\").strip().lower()\n",
    "                confidence = float(data.get(\"confidence\", 0.0))\n",
    "                explanation = data.get(\"explanation\", \"\")\n",
    "\n",
    "                label_counts[label] += 1\n",
    "                confidence_sums[label] += confidence\n",
    "                confidence_counts[label] += 1\n",
    "                explanations.append(f\"{label} ({confidence:.2f}): {explanation}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Error in file {file.name}: {e}\")\n",
    "\n",
    "    # Compute average confidence per label\n",
    "    avg_confidences = {\n",
    "        label: round(confidence_sums[label] / confidence_counts[label], 3)\n",
    "        for label in label_counts\n",
    "    }\n",
    "\n",
    "    # Weighted vote = label with highest total confidence\n",
    "    weighted_vote = max(confidence_sums.items(), key=lambda x: x[1])[0] if confidence_sums else None\n",
    "\n",
    "    aggregated_results.append({\n",
    "        \"subtitle_filename\": movie_id,\n",
    "        \"label_counts\": dict(label_counts),\n",
    "        \"avg_confidences\": avg_confidences,\n",
    "        \"weighted_vote\": weighted_vote,\n",
    "        \"explanations\": explanations\n",
    "    })\n",
    "\n",
    "# === Save to CSV ===\n",
    "df = pd.DataFrame(aggregated_results)\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"âœ… Saved aggregated results to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b76ad1-6984-4eab-bece-81ed28146a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Evaluation complete:\n",
      "âœ… Correct: 16/20\n",
      "ðŸ“Š Accuracy: 80.00%\n",
      "ðŸ“ Saved to: /Users/cedricroetheli/Desktop/Benchmark/good_vs_evil_evaluation_grok.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths ===\n",
    "base = Path.home() / \"Desktop\" / \"Benchmark\"\n",
    "truth_path = base / \"benchmark_final.csv\"\n",
    "model_path = base / \"model_good_vs_evil_output_grok.csv\"\n",
    "output_path = base / \"good_vs_evil_evaluation_grok.csv\"\n",
    "\n",
    "# === Load Data ===\n",
    "truth_df = pd.read_csv(truth_path)\n",
    "model_df = pd.read_csv(model_path)\n",
    "\n",
    "# === Normalize filenames ===\n",
    "truth_df[\"subtitle_filename\"] = truth_df[\"subtitle_filename\"].str.strip()\n",
    "model_df[\"subtitle_filename\"] = model_df[\"subtitle_filename\"].str.strip()\n",
    "\n",
    "# === Label Mapping for Consistency ===\n",
    "label_map = {\n",
    "    \"clear\": \"clear\",\n",
    "    \"complicated\": \"complicated\",\n",
    "    \"complex\": \"complicated\",  # âœ… map 'complex' to 'complicated'\n",
    "    \"neutral\": \"neutral\"\n",
    "}\n",
    "\n",
    "def normalize_label(label):\n",
    "    if pd.isna(label):\n",
    "        return \"\"\n",
    "    label = label.lower().strip()\n",
    "    return label_map.get(label, label)\n",
    "\n",
    "def normalize_set(label_str):\n",
    "    if pd.isna(label_str):\n",
    "        return set()\n",
    "    parts = [normalize_label(part) for part in label_str.split(\"|\")]\n",
    "    return set(parts)\n",
    "\n",
    "truth_df[\"good_vs_evil_set\"] = truth_df[\"good_vs_evil\"].apply(normalize_set)\n",
    "model_df[\"normalized_vote\"] = model_df[\"weighted_vote\"].apply(normalize_label)\n",
    "\n",
    "# === Merge and Evaluate ===\n",
    "merged_df = pd.merge(model_df, truth_df, on=\"subtitle_filename\", how=\"inner\")\n",
    "merged_df[\"is_correct\"] = merged_df.apply(\n",
    "    lambda row: row[\"normalized_vote\"] in row[\"good_vs_evil_set\"], axis=1\n",
    ")\n",
    "\n",
    "# === Output CSV ===\n",
    "evaluation_df = merged_df[[\n",
    "    \"subtitle_filename\", \"good_vs_evil\", \"normalized_vote\", \"is_correct\"\n",
    "]].copy()\n",
    "evaluation_df.columns = [\"movie\", \"benchmark_good_vs_evil\", \"model_good_vs_evil\", \"is_correct\"]\n",
    "evaluation_df.to_csv(output_path, index=False)\n",
    "\n",
    "# === Summary ===\n",
    "total = len(evaluation_df)\n",
    "correct = evaluation_df[\"is_correct\"].sum()\n",
    "accuracy = correct / total if total else 0\n",
    "\n",
    "print(f\"ðŸŽ¯ Evaluation complete:\")\n",
    "print(f\"âœ… Correct: {correct}/{total}\")\n",
    "print(f\"ðŸ“Š Accuracy: {accuracy:.2%}\")\n",
    "print(f\"ðŸ“ Saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c6831-f92d-470b-906f-aa69e2c7e85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_clean_env_py310)",
   "language": "python",
   "name": "my_clean_env_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
