{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "032eb2c7-160c-443f-bee7-41fc1bfc46d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:   0%|                       | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2006Blood.Diamond chunk 1\n",
      "✅ Scored: 2006Blood.Diamond chunk 2\n",
      "✅ Scored: 2006Blood.Diamond chunk 3\n",
      "✅ Scored: 2006Blood.Diamond chunk 4\n",
      "✅ Scored: 2006Blood.Diamond chunk 5\n",
      "✅ Scored: 2006Blood.Diamond chunk 6\n",
      "✅ Scored: 2006Blood.Diamond chunk 7\n",
      "✅ Scored: 2006Blood.Diamond chunk 8\n",
      "✅ Scored: 2006Blood.Diamond chunk 9\n",
      "✅ Scored: 2006Blood.Diamond chunk 10\n",
      "✅ Scored: 2006Blood.Diamond chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:   5%|▊              | 1/20 [01:05<20:38, 65.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2005The.Constant.Gardener chunk 1\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 2\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 3\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 4\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 5\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 6\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 7\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 8\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 9\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 10\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 11\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 12\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  10%|█▌             | 2/20 [02:26<22:23, 74.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 1\n",
      "✅ Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 2\n",
      "✅ Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 3\n",
      "✅ Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 4\n",
      "✅ Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 5\n",
      "✅ Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  15%|██▎            | 3/20 [02:59<15:48, 55.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2009Avatar chunk 1\n",
      "✅ Scored: 2009Avatar chunk 2\n",
      "✅ Scored: 2009Avatar chunk 3\n",
      "✅ Scored: 2009Avatar chunk 4\n",
      "✅ Scored: 2009Avatar chunk 5\n",
      "✅ Scored: 2009Avatar chunk 6\n",
      "✅ Scored: 2009Avatar chunk 7\n",
      "✅ Scored: 2009Avatar chunk 8\n",
      "✅ Scored: 2009Avatar chunk 9\n",
      "✅ Scored: 2009Avatar chunk 10\n",
      "✅ Scored: 2009Avatar chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  20%|███            | 4/20 [04:01<15:32, 58.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2012The.Hunger.Games chunk 1\n",
      "✅ Scored: 2012The.Hunger.Games chunk 2\n",
      "✅ Scored: 2012The.Hunger.Games chunk 3\n",
      "✅ Scored: 2012The.Hunger.Games chunk 4\n",
      "✅ Scored: 2012The.Hunger.Games chunk 5\n",
      "✅ Scored: 2012The.Hunger.Games chunk 6\n",
      "✅ Scored: 2012The.Hunger.Games chunk 7\n",
      "✅ Scored: 2012The.Hunger.Games chunk 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  25%|███▊           | 5/20 [04:46<13:21, 53.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1984Ghostbusters chunk 1\n",
      "✅ Scored: 1984Ghostbusters chunk 2\n",
      "✅ Scored: 1984Ghostbusters chunk 3\n",
      "✅ Scored: 1984Ghostbusters chunk 4\n",
      "✅ Scored: 1984Ghostbusters chunk 5\n",
      "✅ Scored: 1984Ghostbusters chunk 6\n",
      "✅ Scored: 1984Ghostbusters chunk 7\n",
      "✅ Scored: 1984Ghostbusters chunk 8\n",
      "✅ Scored: 1984Ghostbusters chunk 9\n",
      "✅ Scored: 1984Ghostbusters chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  30%|████▌          | 6/20 [05:43<12:43, 54.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1978Superman chunk 1\n",
      "✅ Scored: 1978Superman chunk 2\n",
      "✅ Scored: 1978Superman chunk 3\n",
      "✅ Scored: 1978Superman chunk 4\n",
      "✅ Scored: 1978Superman chunk 5\n",
      "✅ Scored: 1978Superman chunk 6\n",
      "✅ Scored: 1978Superman chunk 7\n",
      "✅ Scored: 1978Superman chunk 8\n",
      "✅ Scored: 1978Superman chunk 9\n",
      "✅ Scored: 1978Superman chunk 10\n",
      "✅ Scored: 1978Superman chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  35%|█████▎         | 7/20 [06:38<11:52, 54.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2008The.Hurt.Locker chunk 1\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 2\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 3\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 4\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 5\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 6\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 7\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 8\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  40%|██████         | 8/20 [07:33<10:55, 54.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 1\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 2\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 3\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 4\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 5\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 6\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 7\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 8\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 9\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 10\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 11\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  45%|██████▊        | 9/20 [08:37<10:35, 57.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 1\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 2\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 3\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 4\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 5\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 6\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 7\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 8\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 9\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  50%|███████       | 10/20 [09:39<09:50, 59.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2018Black.Panther chunk 1\n",
      "✅ Scored: 2018Black.Panther chunk 2\n",
      "✅ Scored: 2018Black.Panther chunk 3\n",
      "✅ Scored: 2018Black.Panther chunk 4\n",
      "✅ Scored: 2018Black.Panther chunk 5\n",
      "✅ Scored: 2018Black.Panther chunk 6\n",
      "✅ Scored: 2018Black.Panther chunk 7\n",
      "✅ Scored: 2018Black.Panther chunk 8\n",
      "✅ Scored: 2018Black.Panther chunk 9\n",
      "✅ Scored: 2018Black.Panther chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  55%|███████▋      | 11/20 [10:34<08:39, 57.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2021Dont.Look.Up chunk 1\n",
      "✅ Scored: 2021Dont.Look.Up chunk 2\n",
      "✅ Scored: 2021Dont.Look.Up chunk 3\n",
      "✅ Scored: 2021Dont.Look.Up chunk 4\n",
      "✅ Scored: 2021Dont.Look.Up chunk 5\n",
      "✅ Scored: 2021Dont.Look.Up chunk 6\n",
      "✅ Scored: 2021Dont.Look.Up chunk 7\n",
      "✅ Scored: 2021Dont.Look.Up chunk 8\n",
      "✅ Scored: 2021Dont.Look.Up chunk 9\n",
      "✅ Scored: 2021Dont.Look.Up chunk 10\n",
      "✅ Scored: 2021Dont.Look.Up chunk 11\n",
      "✅ Scored: 2021Dont.Look.Up chunk 12\n",
      "✅ Scored: 2021Dont.Look.Up chunk 13\n",
      "✅ Scored: 2021Dont.Look.Up chunk 14\n",
      "✅ Scored: 2021Dont.Look.Up chunk 15\n",
      "✅ Scored: 2021Dont.Look.Up chunk 16\n",
      "✅ Scored: 2021Dont.Look.Up chunk 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  60%|████████▍     | 12/20 [12:19<09:38, 72.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1982First.Blood chunk 1\n",
      "✅ Scored: 1982First.Blood chunk 2\n",
      "✅ Scored: 1982First.Blood chunk 3\n",
      "✅ Scored: 1982First.Blood chunk 4\n",
      "✅ Scored: 1982First.Blood chunk 5\n",
      "✅ Scored: 1982First.Blood chunk 6\n",
      "✅ Scored: 1982First.Blood chunk 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  65%|█████████     | 13/20 [13:01<07:21, 63.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2019Joker chunk 1\n",
      "✅ Scored: 2019Joker chunk 2\n",
      "✅ Scored: 2019Joker chunk 3\n",
      "✅ Scored: 2019Joker chunk 4\n",
      "✅ Scored: 2019Joker chunk 5\n",
      "✅ Scored: 2019Joker chunk 6\n",
      "✅ Scored: 2019Joker chunk 7\n",
      "✅ Scored: 2019Joker chunk 8\n",
      "✅ Scored: 2019Joker chunk 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  70%|█████████▊    | 14/20 [13:49<05:50, 58.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2006Night.at.the.Museum chunk 1\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 2\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 3\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 4\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 5\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 6\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 7\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 8\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 9\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  75%|██████████▌   | 15/20 [14:53<05:01, 60.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1976Rocky.I chunk 1\n",
      "✅ Scored: 1976Rocky.I chunk 2\n",
      "✅ Scored: 1976Rocky.I chunk 3\n",
      "✅ Scored: 1976Rocky.I chunk 4\n",
      "✅ Scored: 1976Rocky.I chunk 5\n",
      "✅ Scored: 1976Rocky.I chunk 6\n",
      "✅ Scored: 1976Rocky.I chunk 7\n",
      "✅ Scored: 1976Rocky.I chunk 8\n",
      "✅ Scored: 1976Rocky.I chunk 9\n",
      "✅ Scored: 1976Rocky.I chunk 10\n",
      "✅ Scored: 1976Rocky.I chunk 11\n",
      "✅ Scored: 1976Rocky.I chunk 12\n",
      "✅ Scored: 1976Rocky.I chunk 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  80%|███████████▏  | 16/20 [16:04<04:13, 63.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2005V.for.Vendetta chunk 1\n",
      "✅ Scored: 2005V.for.Vendetta chunk 2\n",
      "✅ Scored: 2005V.for.Vendetta chunk 3\n",
      "✅ Scored: 2005V.for.Vendetta chunk 4\n",
      "✅ Scored: 2005V.for.Vendetta chunk 5\n",
      "✅ Scored: 2005V.for.Vendetta chunk 6\n",
      "✅ Scored: 2005V.for.Vendetta chunk 7\n",
      "✅ Scored: 2005V.for.Vendetta chunk 8\n",
      "✅ Scored: 2005V.for.Vendetta chunk 9\n",
      "✅ Scored: 2005V.for.Vendetta chunk 10\n",
      "✅ Scored: 2005V.for.Vendetta chunk 11\n",
      "✅ Scored: 2005V.for.Vendetta chunk 12\n",
      "✅ Scored: 2005V.for.Vendetta chunk 13\n",
      "✅ Scored: 2005V.for.Vendetta chunk 14\n",
      "✅ Scored: 2005V.for.Vendetta chunk 15\n",
      "✅ Scored: 2005V.for.Vendetta chunk 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  85%|███████████▉  | 17/20 [17:35<03:35, 71.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2017Paddington.2 chunk 1\n",
      "✅ Scored: 2017Paddington.2 chunk 2\n",
      "✅ Scored: 2017Paddington.2 chunk 3\n",
      "✅ Scored: 2017Paddington.2 chunk 4\n",
      "✅ Scored: 2017Paddington.2 chunk 5\n",
      "✅ Scored: 2017Paddington.2 chunk 6\n",
      "✅ Scored: 2017Paddington.2 chunk 7\n",
      "✅ Scored: 2017Paddington.2 chunk 8\n",
      "✅ Scored: 2017Paddington.2 chunk 9\n",
      "✅ Scored: 2017Paddington.2 chunk 10\n",
      "✅ Scored: 2017Paddington.2 chunk 11\n",
      "✅ Scored: 2017Paddington.2 chunk 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  90%|████████████▌ | 18/20 [18:41<02:19, 69.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1985Back.To.The.Future chunk 1\n",
      "✅ Scored: 1985Back.To.The.Future chunk 2\n",
      "✅ Scored: 1985Back.To.The.Future chunk 3\n",
      "✅ Scored: 1985Back.To.The.Future chunk 4\n",
      "✅ Scored: 1985Back.To.The.Future chunk 5\n",
      "✅ Scored: 1985Back.To.The.Future chunk 6\n",
      "✅ Scored: 1985Back.To.The.Future chunk 7\n",
      "✅ Scored: 1985Back.To.The.Future chunk 8\n",
      "✅ Scored: 1985Back.To.The.Future chunk 9\n",
      "✅ Scored: 1985Back.To.The.Future chunk 10\n",
      "✅ Scored: 1985Back.To.The.Future chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok:  95%|█████████████▎| 19/20 [19:38<01:06, 66.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2013The.Purge chunk 1\n",
      "✅ Scored: 2013The.Purge chunk 2\n",
      "✅ Scored: 2013The.Purge chunk 3\n",
      "✅ Scored: 2013The.Purge chunk 4\n",
      "✅ Scored: 2013The.Purge chunk 5\n",
      "✅ Scored: 2013The.Purge chunk 6\n",
      "✅ Scored: 2013The.Purge chunk 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type with Grok: 100%|██████████████| 20/20 [20:19<00:00, 60.98s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === xAI Grok API setup ===\n",
    "api_key = \"api-key\"  # 🔒 Replace with your secure token\n",
    "api_url = \"https://api.x.ai/v1/chat/completions\"\n",
    "model_name = \"grok-3-mini\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# === Paths ===\n",
    "base = Path.home() / \"Desktop\" / \"Benchmark\"\n",
    "subs_dir = base / \"json_benchmark\"\n",
    "summaries_dir = base / \"summaries\"\n",
    "output_dir = base / \"scored_hero_type_grok\"\n",
    "prompts_dir = base / \"prompts_hero_type_grok\"\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "prompts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Load match file ===\n",
    "matches_df = pd.read_csv(\"matches_benchmark.csv\")\n",
    "\n",
    "# === Prompt template ===\n",
    "def create_hero_type_prompt(summary, chunk):\n",
    "    return f\"\"\"\n",
    "You are analyzing the protagonist(s) of a film based on its subtitles and plot summary.\n",
    "\n",
    "Your task is to classify the central figure(s) in the film into one of six predefined hero type categories.\n",
    "\n",
    "The six hero type categories are defined as follows:\n",
    "\n",
    "- Ordinary Individual: A regular person caught in extraordinary circumstances; succeeds through grit, not destiny.\n",
    "- Heroic Individual: A character with clear heroic traits—bravery, leadership, strength, often iconic or idealized.\n",
    "- Group / Ensemble: A collective effort drives the story; no single person is the exclusive hero.\n",
    "- Institution / System: An organization or societal body serves as protagonist or moral force.\n",
    "- None: There is no clear hero in the film.\n",
    "- Anti-Hero: The main character may be active but is morally ambiguous, selfish, or destructive.\n",
    "\n",
    "Please:\n",
    "1. Select the most appropriate hero type label\n",
    "2. Provide a brief explanation (1–2 sentences max)\n",
    "3. Include a confidence score from 0.0 to 1.0\n",
    "\n",
    "Strictly return your answer in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"hero_type\": \"...\",\n",
    "  \"confidence\": ...,\n",
    "  \"explanation\": \"...\"\n",
    "}}\n",
    "\n",
    "Film Summary:\n",
    "\\\"\\\"\\\"{summary}\\\"\\\"\\\"\n",
    "\n",
    "Dialogue:\n",
    "\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\n",
    "\"\"\".strip()\n",
    "\n",
    "# === API call to Grok ===\n",
    "def call_grok(prompt):\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"temperature\": 0,\n",
    "        \"stream\": False,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a careful film analyst. Always return exactly and only the required JSON.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(api_url, headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code == 429:\n",
    "        print(\"⚠️ Rate limit hit. Waiting...\")\n",
    "        time.sleep(60)\n",
    "        return call_grok(prompt)\n",
    "    elif response.status_code != 200:\n",
    "        print(f\"❌ API Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return json.loads(content)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ JSON parsing error:\\n{response.text}\")\n",
    "        return None\n",
    "\n",
    "# === Subtitle chunking ===\n",
    "def chunk_dialogue(subs, chunk_size=5000, overlap=200):\n",
    "    text_blocks = [line.get(\"text\", \"\").strip() for line in subs if line.get(\"text\")]\n",
    "    full_text = \" \".join(text_blocks)\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(full_text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(full_text[start:end])\n",
    "        start = end - overlap\n",
    "    return chunks\n",
    "\n",
    "# === Main loop ===\n",
    "for _, row in tqdm(matches_df.iterrows(), total=len(matches_df), desc=\"Scoring hero type with Grok\"):\n",
    "    filename = row[\"subtitle_filename\"]\n",
    "    json_path = subs_dir / f\"{filename}.json\"\n",
    "    summary_path = summaries_dir / f\"{filename}.srt_summary.txt\"\n",
    "\n",
    "    if not json_path.exists() or not summary_path.exists():\n",
    "        print(f\"⚠️ Missing files for: {filename}\")\n",
    "        continue\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        subs = json.load(f)\n",
    "\n",
    "    with open(summary_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        summary = f.read().strip()\n",
    "\n",
    "    chunks = chunk_dialogue(subs)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        output_path = output_dir / f\"{filename}_chunk{i+1}_hero_type.json\"\n",
    "        prompt_path = prompts_dir / f\"{filename}_chunk{i+1}_hero_type_prompt.txt\"\n",
    "\n",
    "        if output_path.exists():\n",
    "            print(f\"🟡 Already scored: {filename} chunk {i+1}\")\n",
    "            continue\n",
    "\n",
    "        prompt = create_hero_type_prompt(summary, chunk)\n",
    "\n",
    "        # Save prompt for transparency\n",
    "        with open(prompt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(prompt)\n",
    "\n",
    "        result = call_grok(prompt)\n",
    "        if result:\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(result, f, indent=2)\n",
    "            print(f\"✅ Scored: {filename} chunk {i+1}\")\n",
    "        else:\n",
    "            print(f\"❌ Failed: {filename} chunk {i+1}\")\n",
    "\n",
    "        time.sleep(1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf5518-4dee-4548-bfba-be1c19b7f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# === Paths ===\n",
    "base_path = Path.home() / \"Desktop\" / \"Benchmark\"\n",
    "scored_dir = base_path / \"scored_hero_type_grok\"\n",
    "output_csv_path = base_path / \"model_hero_type_output_grok.csv\"\n",
    "\n",
    "# === Aggregate Results ===\n",
    "aggregated_results = []\n",
    "\n",
    "# Group chunk files by movie\n",
    "movie_files = defaultdict(list)\n",
    "for file in scored_dir.glob(\"*_chunk*_hero_type.json\"):\n",
    "    movie_id = file.name.split(\"_chunk\")[0]\n",
    "    movie_files[movie_id].append(file)\n",
    "\n",
    "# Process each movie's chunks\n",
    "for movie_id, files in movie_files.items():\n",
    "    label_counts = Counter()\n",
    "    confidence_sums = defaultdict(float)\n",
    "    confidence_counts = defaultdict(int)\n",
    "    explanations = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                label = data.get(\"hero_type\", \"\").strip().lower()\n",
    "                confidence = float(data.get(\"confidence\", 0.0))\n",
    "                explanation = data.get(\"explanation\", \"\")\n",
    "\n",
    "                label_counts[label] += 1\n",
    "                confidence_sums[label] += confidence\n",
    "                confidence_counts[label] += 1\n",
    "                explanations.append(f\"{label} ({confidence:.2f}): {explanation}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error in file {file.name}: {e}\")\n",
    "\n",
    "    # Compute average confidence per label\n",
    "    avg_confidences = {\n",
    "        label: round(confidence_sums[label] / confidence_counts[label], 3)\n",
    "        for label in label_counts\n",
    "    }\n",
    "\n",
    "    # Weighted vote = label with highest total confidence\n",
    "    weighted_vote = max(confidence_sums.items(), key=lambda x: x[1])[0] if confidence_sums else None\n",
    "\n",
    "    aggregated_results.append({\n",
    "        \"subtitle_filename\": movie_id,\n",
    "        \"label_counts\": dict(label_counts),\n",
    "        \"avg_confidences\": avg_confidences,\n",
    "        \"weighted_vote\": weighted_vote,\n",
    "        \"explanations\": explanations\n",
    "    })\n",
    "\n",
    "# === Save to CSV ===\n",
    "df = pd.DataFrame(aggregated_results)\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"✅ Saved aggregated results to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca16770-77f0-4127-8e36-c1049f8f1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths ===\n",
    "base = Path.home() / \"Desktop\" / \"Benchmark\"\n",
    "truth_path = base / \"benchmark_final.csv\"\n",
    "model_path = base / \"model_hero_type_output_grok.csv\"\n",
    "output_path = base / \"hero_type_evaluation_grok.csv\"\n",
    "\n",
    "# === Load Data ===\n",
    "truth_df = pd.read_csv(truth_path)\n",
    "model_df = pd.read_csv(model_path)\n",
    "\n",
    "# === Normalize filenames for matching ===\n",
    "truth_df[\"subtitle_filename\"] = truth_df[\"subtitle_filename\"].str.strip()\n",
    "model_df[\"subtitle_filename\"] = model_df[\"subtitle_filename\"].str.strip()\n",
    "\n",
    "# === Define Label Normalization ===\n",
    "label_map = {\n",
    "    \"heroic individual\": \"heroic\",\n",
    "    \"ordinary individual\": \"ordinary\",\n",
    "    \"group / ensemble\": \"group\",\n",
    "    \"institution / system\": \"institution\",\n",
    "    \"none\": \"none\",\n",
    "    \"anti-heroic\": \"anti-hero\",\n",
    "    \"none / anti-heroic\": \"none|anti-hero\",\n",
    "    \"none|anti-heroic\": \"none|anti-hero\",\n",
    "    \"anti-hero\": \"anti-hero\",\n",
    "    \"none / anti-hero\": \"none|anti-hero\",\n",
    "    \"group\": \"group\",\n",
    "    \"heroic\": \"heroic\",\n",
    "    \"ordinary\": \"ordinary\"\n",
    "}\n",
    "\n",
    "# Apply label map to both sides\n",
    "def normalize_label(label):\n",
    "    if pd.isna(label):\n",
    "        return \"\"\n",
    "    label = label.lower().strip()\n",
    "    return label_map.get(label, label)\n",
    "\n",
    "# Normalize benchmark labels (which may have multiple correct ones)\n",
    "def normalize_set(label_str):\n",
    "    if pd.isna(label_str):\n",
    "        return set()\n",
    "    parts = [normalize_label(part) for part in label_str.split(\"|\")]\n",
    "    return set(parts)\n",
    "\n",
    "truth_df[\"hero_type_set\"] = truth_df[\"hero_type\"].apply(normalize_set)\n",
    "model_df[\"normalized_vote\"] = model_df[\"weighted_vote\"].apply(normalize_label)\n",
    "\n",
    "# === Merge and Evaluate ===\n",
    "merged_df = pd.merge(model_df, truth_df, on=\"subtitle_filename\", how=\"inner\")\n",
    "merged_df[\"is_correct\"] = merged_df.apply(\n",
    "    lambda row: row[\"normalized_vote\"] in row[\"hero_type_set\"], axis=1\n",
    ")\n",
    "\n",
    "# === Prepare Output CSV ===\n",
    "evaluation_df = merged_df[[\n",
    "    \"subtitle_filename\", \"hero_type\", \"normalized_vote\", \"is_correct\"\n",
    "]].copy()\n",
    "evaluation_df.columns = [\"movie\", \"benchmark_hero_type\", \"model_hero_type\", \"is_correct\"]\n",
    "evaluation_df.to_csv(output_path, index=False)\n",
    "\n",
    "# === Summary ===\n",
    "total = len(evaluation_df)\n",
    "correct = evaluation_df[\"is_correct\"].sum()\n",
    "accuracy = correct / total if total else 0\n",
    "\n",
    "print(f\"🎯 Evaluation complete:\")\n",
    "print(f\"✅ Correct: {correct}/{total}\")\n",
    "print(f\"📊 Accuracy: {accuracy:.2%}\")\n",
    "print(f\"📁 Saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_clean_env_py310)",
   "language": "python",
   "name": "my_clean_env_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
