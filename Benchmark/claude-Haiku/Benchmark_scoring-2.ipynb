{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e02bec4-a289-4521-9afd-5ccd8ebad847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:   0%|                                 | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2006Blood.Diamond chunk 1\n",
      "✅ Scored: 2006Blood.Diamond chunk 2\n",
      "✅ Scored: 2006Blood.Diamond chunk 3\n",
      "✅ Scored: 2006Blood.Diamond chunk 4\n",
      "✅ Scored: 2006Blood.Diamond chunk 5\n",
      "✅ Scored: 2006Blood.Diamond chunk 6\n",
      "✅ Scored: 2006Blood.Diamond chunk 7\n",
      "✅ Scored: 2006Blood.Diamond chunk 8\n",
      "✅ Scored: 2006Blood.Diamond chunk 9\n",
      "✅ Scored: 2006Blood.Diamond chunk 10\n",
      "✅ Scored: 2006Blood.Diamond chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:   5%|█▎                       | 1/20 [00:31<09:54, 31.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2005The.Constant.Gardener chunk 1\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 2\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 3\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 4\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 5\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 6\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 7\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 8\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 9\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 10\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 11\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 12\n",
      "✅ Scored: 2005The.Constant.Gardener chunk 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  10%|██▌                      | 2/20 [01:07<10:16, 34.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 1\n",
      "✅ Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 2\n",
      "✅ Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 3\n",
      "✅ Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 4\n",
      "✅ Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 5\n",
      "✅ Scored: 1981Indiana.Jones.And.The.Raiders.Of.The.Lost.Ark chunk 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  15%|███▊                     | 3/20 [01:24<07:29, 26.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2009Avatar chunk 1\n",
      "✅ Scored: 2009Avatar chunk 2\n",
      "✅ Scored: 2009Avatar chunk 3\n",
      "✅ Scored: 2009Avatar chunk 4\n",
      "✅ Scored: 2009Avatar chunk 5\n",
      "✅ Scored: 2009Avatar chunk 6\n",
      "✅ Scored: 2009Avatar chunk 7\n",
      "✅ Scored: 2009Avatar chunk 8\n",
      "✅ Scored: 2009Avatar chunk 9\n",
      "✅ Scored: 2009Avatar chunk 10\n",
      "✅ Scored: 2009Avatar chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  20%|█████                    | 4/20 [01:56<07:38, 28.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2012The.Hunger.Games chunk 1\n",
      "✅ Scored: 2012The.Hunger.Games chunk 2\n",
      "✅ Scored: 2012The.Hunger.Games chunk 3\n",
      "✅ Scored: 2012The.Hunger.Games chunk 4\n",
      "✅ Scored: 2012The.Hunger.Games chunk 5\n",
      "✅ Scored: 2012The.Hunger.Games chunk 6\n",
      "✅ Scored: 2012The.Hunger.Games chunk 7\n",
      "✅ Scored: 2012The.Hunger.Games chunk 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  25%|██████▎                  | 5/20 [02:19<06:39, 26.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1984Ghostbusters chunk 1\n",
      "✅ Scored: 1984Ghostbusters chunk 2\n",
      "✅ Scored: 1984Ghostbusters chunk 3\n",
      "✅ Scored: 1984Ghostbusters chunk 4\n",
      "✅ Scored: 1984Ghostbusters chunk 5\n",
      "✅ Scored: 1984Ghostbusters chunk 6\n",
      "✅ Scored: 1984Ghostbusters chunk 7\n",
      "✅ Scored: 1984Ghostbusters chunk 8\n",
      "✅ Scored: 1984Ghostbusters chunk 9\n",
      "✅ Scored: 1984Ghostbusters chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  30%|███████▌                 | 6/20 [02:49<06:27, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1978Superman chunk 1\n",
      "✅ Scored: 1978Superman chunk 2\n",
      "✅ Scored: 1978Superman chunk 3\n",
      "✅ Scored: 1978Superman chunk 4\n",
      "✅ Scored: 1978Superman chunk 5\n",
      "✅ Scored: 1978Superman chunk 6\n",
      "✅ Scored: 1978Superman chunk 7\n",
      "✅ Scored: 1978Superman chunk 8\n",
      "✅ Scored: 1978Superman chunk 9\n",
      "✅ Scored: 1978Superman chunk 10\n",
      "✅ Scored: 1978Superman chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  35%|████████▊                | 7/20 [03:21<06:19, 29.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2008The.Hurt.Locker chunk 1\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 2\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 3\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 4\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 5\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 6\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 7\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 8\n",
      "✅ Scored: 2008The.Hurt.Locker chunk 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  40%|██████████               | 8/20 [03:50<05:47, 28.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 1\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 2\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 3\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 4\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 5\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 6\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 7\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 8\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 9\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 10\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 11\n",
      "✅ Scored: 1977Star.Wars.Episode.IV.-.A.New.Hope chunk 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  45%|███████████▎             | 9/20 [04:36<06:16, 34.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 1\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 2\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 3\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 4\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 5\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 6\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 7\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 8\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 9\n",
      "✅ Scored: 2003Pirates.of.the.Caribbean.The.Curse.of.the.Black.Pearl chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  50%|████████████            | 10/20 [05:03<05:21, 32.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2018Black.Panther chunk 1\n",
      "✅ Scored: 2018Black.Panther chunk 2\n",
      "✅ Scored: 2018Black.Panther chunk 3\n",
      "✅ Scored: 2018Black.Panther chunk 4\n",
      "✅ Scored: 2018Black.Panther chunk 5\n",
      "✅ Scored: 2018Black.Panther chunk 6\n",
      "✅ Scored: 2018Black.Panther chunk 7\n",
      "✅ Scored: 2018Black.Panther chunk 8\n",
      "✅ Scored: 2018Black.Panther chunk 9\n",
      "✅ Scored: 2018Black.Panther chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  55%|█████████████▏          | 11/20 [05:32<04:40, 31.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2021Dont.Look.Up chunk 1\n",
      "✅ Scored: 2021Dont.Look.Up chunk 2\n",
      "✅ Scored: 2021Dont.Look.Up chunk 3\n",
      "✅ Scored: 2021Dont.Look.Up chunk 4\n",
      "✅ Scored: 2021Dont.Look.Up chunk 5\n",
      "✅ Scored: 2021Dont.Look.Up chunk 6\n",
      "✅ Scored: 2021Dont.Look.Up chunk 7\n",
      "✅ Scored: 2021Dont.Look.Up chunk 8\n",
      "✅ Scored: 2021Dont.Look.Up chunk 9\n",
      "✅ Scored: 2021Dont.Look.Up chunk 10\n",
      "✅ Scored: 2021Dont.Look.Up chunk 11\n",
      "✅ Scored: 2021Dont.Look.Up chunk 12\n",
      "✅ Scored: 2021Dont.Look.Up chunk 13\n",
      "✅ Scored: 2021Dont.Look.Up chunk 14\n",
      "✅ Scored: 2021Dont.Look.Up chunk 15\n",
      "✅ Scored: 2021Dont.Look.Up chunk 16\n",
      "✅ Scored: 2021Dont.Look.Up chunk 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  60%|██████████████▍         | 12/20 [06:22<04:54, 36.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1982First.Blood chunk 1\n",
      "✅ Scored: 1982First.Blood chunk 2\n",
      "✅ Scored: 1982First.Blood chunk 3\n",
      "✅ Scored: 1982First.Blood chunk 4\n",
      "✅ Scored: 1982First.Blood chunk 5\n",
      "✅ Scored: 1982First.Blood chunk 6\n",
      "✅ Scored: 1982First.Blood chunk 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  65%|███████████████▌        | 13/20 [06:41<03:40, 31.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2019Joker chunk 1\n",
      "✅ Scored: 2019Joker chunk 2\n",
      "✅ Scored: 2019Joker chunk 3\n",
      "✅ Scored: 2019Joker chunk 4\n",
      "✅ Scored: 2019Joker chunk 5\n",
      "✅ Scored: 2019Joker chunk 6\n",
      "✅ Scored: 2019Joker chunk 7\n",
      "✅ Scored: 2019Joker chunk 8\n",
      "✅ Scored: 2019Joker chunk 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  70%|████████████████▊       | 14/20 [07:08<03:00, 30.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2006Night.at.the.Museum chunk 1\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 2\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 3\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 4\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 5\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 6\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 7\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 8\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 9\n",
      "✅ Scored: 2006Night.at.the.Museum chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  75%|██████████████████      | 15/20 [07:37<02:28, 29.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1976Rocky.I chunk 1\n",
      "✅ Scored: 1976Rocky.I chunk 2\n",
      "✅ Scored: 1976Rocky.I chunk 3\n",
      "✅ Scored: 1976Rocky.I chunk 4\n",
      "✅ Scored: 1976Rocky.I chunk 5\n",
      "✅ Scored: 1976Rocky.I chunk 6\n",
      "✅ Scored: 1976Rocky.I chunk 7\n",
      "✅ Scored: 1976Rocky.I chunk 8\n",
      "✅ Scored: 1976Rocky.I chunk 9\n",
      "✅ Scored: 1976Rocky.I chunk 10\n",
      "✅ Scored: 1976Rocky.I chunk 11\n",
      "✅ Scored: 1976Rocky.I chunk 12\n",
      "✅ Scored: 1976Rocky.I chunk 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  80%|███████████████████▏    | 16/20 [08:14<02:07, 31.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2005V.for.Vendetta chunk 1\n",
      "✅ Scored: 2005V.for.Vendetta chunk 2\n",
      "✅ Scored: 2005V.for.Vendetta chunk 3\n",
      "✅ Scored: 2005V.for.Vendetta chunk 4\n",
      "✅ Scored: 2005V.for.Vendetta chunk 5\n",
      "✅ Scored: 2005V.for.Vendetta chunk 6\n",
      "✅ Scored: 2005V.for.Vendetta chunk 7\n",
      "✅ Scored: 2005V.for.Vendetta chunk 8\n",
      "✅ Scored: 2005V.for.Vendetta chunk 9\n",
      "✅ Scored: 2005V.for.Vendetta chunk 10\n",
      "✅ Scored: 2005V.for.Vendetta chunk 11\n",
      "✅ Scored: 2005V.for.Vendetta chunk 12\n",
      "✅ Scored: 2005V.for.Vendetta chunk 13\n",
      "✅ Scored: 2005V.for.Vendetta chunk 14\n",
      "✅ Scored: 2005V.for.Vendetta chunk 15\n",
      "✅ Scored: 2005V.for.Vendetta chunk 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  85%|████████████████████▍   | 17/20 [09:02<01:50, 36.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2017Paddington.2 chunk 1\n",
      "✅ Scored: 2017Paddington.2 chunk 2\n",
      "✅ Scored: 2017Paddington.2 chunk 3\n",
      "✅ Scored: 2017Paddington.2 chunk 4\n",
      "✅ Scored: 2017Paddington.2 chunk 5\n",
      "✅ Scored: 2017Paddington.2 chunk 6\n",
      "✅ Scored: 2017Paddington.2 chunk 7\n",
      "✅ Scored: 2017Paddington.2 chunk 8\n",
      "✅ Scored: 2017Paddington.2 chunk 9\n",
      "✅ Scored: 2017Paddington.2 chunk 10\n",
      "✅ Scored: 2017Paddington.2 chunk 11\n",
      "✅ Scored: 2017Paddington.2 chunk 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  90%|█████████████████████▌  | 18/20 [09:36<01:12, 36.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 1985Back.To.The.Future chunk 1\n",
      "✅ Scored: 1985Back.To.The.Future chunk 2\n",
      "✅ Scored: 1985Back.To.The.Future chunk 3\n",
      "⚠️ Rate limit hit. Waiting...\n",
      "✅ Scored: 1985Back.To.The.Future chunk 4\n",
      "✅ Scored: 1985Back.To.The.Future chunk 5\n",
      "✅ Scored: 1985Back.To.The.Future chunk 6\n",
      "✅ Scored: 1985Back.To.The.Future chunk 7\n",
      "✅ Scored: 1985Back.To.The.Future chunk 8\n",
      "✅ Scored: 1985Back.To.The.Future chunk 9\n",
      "✅ Scored: 1985Back.To.The.Future chunk 10\n",
      "✅ Scored: 1985Back.To.The.Future chunk 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type:  95%|██████████████████████▊ | 19/20 [11:17<00:55, 55.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scored: 2013The.Purge chunk 1\n",
      "✅ Scored: 2013The.Purge chunk 2\n",
      "✅ Scored: 2013The.Purge chunk 3\n",
      "✅ Scored: 2013The.Purge chunk 4\n",
      "✅ Scored: 2013The.Purge chunk 5\n",
      "✅ Scored: 2013The.Purge chunk 6\n",
      "✅ Scored: 2013The.Purge chunk 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring hero type: 100%|████████████████████████| 20/20 [11:36<00:00, 34.85s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Claude API setup ===\n",
    "api_key = \"api-key\"  # 🔒 Insert your key\n",
    "api_url = \"https://api.anthropic.com/v1/messages\"\n",
    "model_name = \"claude-3-haiku-20240307\"\n",
    "\n",
    "headers = {\n",
    "    \"x-api-key\": api_key,\n",
    "    \"anthropic-version\": \"2023-06-01\",\n",
    "    \"content-type\": \"application/json\",\n",
    "}\n",
    "\n",
    "# === Paths ===\n",
    "base = Path.home() / \"Desktop\" / \"Benchmark\"\n",
    "subs_dir = base / \"json_benchmark\"\n",
    "summaries_dir = base / \"summaries\"\n",
    "output_dir = base / \"scored_hero_type\"\n",
    "prompts_dir = base / \"prompts_hero_type\"\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "prompts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Load match file ===\n",
    "matches_df = pd.read_csv(\"matches_benchmark.csv\")\n",
    "\n",
    "# === Prompt template ===\n",
    "def create_hero_type_prompt(summary, chunk):\n",
    "    return f\"\"\"\n",
    "You are analyzing the protagonist(s) of a film based on its subtitles and plot summary.\n",
    "\n",
    "Your task is to classify the central figure(s) in the film into one of six predefined hero type categories.\n",
    "\n",
    "The six hero type categories are defined as follows:\n",
    "\n",
    "- Ordinary Individual: A regular person caught in extraordinary circumstances; succeeds through grit, not destiny.\n",
    "- Heroic Individual: A character with clear heroic traits—bravery, leadership, strength, often iconic or idealized.\n",
    "- Group / Ensemble: A collective effort drives the story; no single person is the exclusive hero.\n",
    "- Institution / System: An organization or societal body serves as protagonist or moral force.\n",
    "- None: There is no clear hero in the film.\n",
    "- Anti-Hero: The main character may be active but is morally ambiguous, selfish, or destructive.\n",
    "\n",
    "Please:\n",
    "1. Select the most appropriate hero type label\n",
    "2. Provide a brief explanation (1–2 sentences max)\n",
    "3. Include a confidence score from 0.0 to 1.0\n",
    "\n",
    "Strictly return your answer in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"hero_type\": \"...\",\n",
    "  \"confidence\": ...,\n",
    "  \"explanation\": \"...\"\n",
    "}}\n",
    "\n",
    "Film Summary:\n",
    "\\\"\\\"\\\"{summary}\\\"\\\"\\\"\n",
    "\n",
    "Dialogue:\n",
    "\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\n",
    "\"\"\".strip()\n",
    "\n",
    "# === API call ===\n",
    "def call_claude(prompt):\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"max_tokens\": 500,\n",
    "        \"temperature\": 0,\n",
    "        \"system\": \"You are a careful film analyst. Always return exactly and only the required JSON.\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "\n",
    "    response = requests.post(api_url, headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code == 429:\n",
    "        print(\"⚠️ Rate limit hit. Waiting...\")\n",
    "        time.sleep(60)\n",
    "        return call_claude(prompt)\n",
    "    elif response.status_code != 200:\n",
    "        print(f\"❌ API Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        content = response.json()[\"content\"][0][\"text\"]\n",
    "        return json.loads(content)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ JSON parsing error:\\n{response.text}\")\n",
    "        return None\n",
    "\n",
    "# === Subtitle chunking ===\n",
    "def chunk_dialogue(subs, chunk_size=5000, overlap=200):\n",
    "    text_blocks = [line.get(\"text\", \"\").strip() for line in subs if line.get(\"text\")]\n",
    "    full_text = \" \".join(text_blocks)\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(full_text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(full_text[start:end])\n",
    "        start = end - overlap\n",
    "    return chunks\n",
    "\n",
    "# === Main loop ===\n",
    "for _, row in tqdm(matches_df.iterrows(), total=len(matches_df), desc=\"Scoring hero type\"):\n",
    "    filename = row[\"subtitle_filename\"]\n",
    "    json_path = subs_dir / f\"{filename}.json\"\n",
    "    summary_path = summaries_dir / f\"{filename}.srt_summary.txt\"\n",
    "\n",
    "    if not json_path.exists() or not summary_path.exists():\n",
    "        print(f\"⚠️ Missing files for: {filename}\")\n",
    "        continue\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        subs = json.load(f)\n",
    "\n",
    "    with open(summary_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        summary = f.read().strip()\n",
    "\n",
    "    chunks = chunk_dialogue(subs)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        output_path = output_dir / f\"{filename}_chunk{i+1}_hero_type.json\"\n",
    "        prompt_path = prompts_dir / f\"{filename}_chunk{i+1}_hero_type_prompt.txt\"\n",
    "\n",
    "        if output_path.exists():\n",
    "            print(f\"🟡 Already scored: {filename} chunk {i+1}\")\n",
    "            continue\n",
    "\n",
    "        prompt = create_hero_type_prompt(summary, chunk)\n",
    "\n",
    "        # Save prompt for transparency\n",
    "        with open(prompt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(prompt)\n",
    "\n",
    "        result = call_claude(prompt)\n",
    "        if result:\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(result, f, indent=2)\n",
    "            print(f\"✅ Scored: {filename} chunk {i+1}\")\n",
    "        else:\n",
    "            print(f\"❌ Failed: {filename} chunk {i+1}\")\n",
    "\n",
    "        time.sleep(1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9991fb84-bc99-4eb8-a0bd-8639eb70bb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved aggregated results to: /Users/cedricroetheli/Desktop/Benchmark/model_hero_type_output.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# === Paths ===\n",
    "base_path = Path.home() / \"Desktop\" / \"Benchmark\"\n",
    "scored_dir = base_path / \"scored_hero_type\"\n",
    "output_csv_path = base_path / \"model_hero_type_output.csv\"\n",
    "\n",
    "# === Aggregate Results ===\n",
    "aggregated_results = []\n",
    "\n",
    "# Group chunk files by movie\n",
    "movie_files = defaultdict(list)\n",
    "for file in scored_dir.glob(\"*_chunk*_hero_type.json\"):\n",
    "    movie_id = file.name.split(\"_chunk\")[0]\n",
    "    movie_files[movie_id].append(file)\n",
    "\n",
    "# Process each movie's chunks\n",
    "for movie_id, files in movie_files.items():\n",
    "    label_counts = Counter()\n",
    "    confidence_sums = defaultdict(float)\n",
    "    confidence_counts = defaultdict(int)\n",
    "    explanations = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                label = data.get(\"hero_type\", \"\").strip().lower()\n",
    "                confidence = float(data.get(\"confidence\", 0.0))\n",
    "                explanation = data.get(\"explanation\", \"\")\n",
    "\n",
    "                label_counts[label] += 1\n",
    "                confidence_sums[label] += confidence\n",
    "                confidence_counts[label] += 1\n",
    "                explanations.append(f\"{label} ({confidence:.2f}): {explanation}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error in file {file.name}: {e}\")\n",
    "\n",
    "    # Compute average confidence per label\n",
    "    avg_confidences = {\n",
    "        label: round(confidence_sums[label] / confidence_counts[label], 3)\n",
    "        for label in label_counts\n",
    "    }\n",
    "\n",
    "    # Weighted vote = label with highest total confidence\n",
    "    weighted_vote = max(confidence_sums.items(), key=lambda x: x[1])[0] if confidence_sums else None\n",
    "\n",
    "    aggregated_results.append({\n",
    "        \"subtitle_filename\": movie_id,\n",
    "        \"label_counts\": dict(label_counts),\n",
    "        \"avg_confidences\": avg_confidences,\n",
    "        \"weighted_vote\": weighted_vote,\n",
    "        \"explanations\": explanations\n",
    "    })\n",
    "\n",
    "# === Save to CSV ===\n",
    "df = pd.DataFrame(aggregated_results)\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"✅ Saved aggregated results to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81344ea7-2120-4c92-9840-bfc3d90a1ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Evaluation complete:\n",
      "✅ Correct: 15/20\n",
      "📊 Accuracy: 75.00%\n",
      "📁 Saved to: /Users/cedricroetheli/Desktop/Benchmark/hero_type_evaluation_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths ===\n",
    "base = Path.home() / \"Desktop\" / \"Benchmark\"\n",
    "truth_path = base / \"benchmark_final.csv\"\n",
    "model_path = base / \"model_hero_type_output.csv\"\n",
    "output_path = base / \"hero_type_evaluation_clean.csv\"\n",
    "\n",
    "# === Load Data ===\n",
    "truth_df = pd.read_csv(truth_path)\n",
    "model_df = pd.read_csv(model_path)\n",
    "\n",
    "# === Normalize filenames for matching ===\n",
    "truth_df[\"subtitle_filename\"] = truth_df[\"subtitle_filename\"].str.strip()\n",
    "model_df[\"subtitle_filename\"] = model_df[\"subtitle_filename\"].str.strip()\n",
    "\n",
    "# === Define Label Normalization ===\n",
    "label_map = {\n",
    "    \"heroic individual\": \"heroic\",\n",
    "    \"ordinary individual\": \"ordinary\",\n",
    "    \"group / ensemble\": \"group\",\n",
    "    \"institution / system\": \"institution\",\n",
    "    \"none\": \"none\",\n",
    "    \"anti-heroic\": \"anti-hero\",\n",
    "    \"none / anti-heroic\": \"none|anti-hero\",\n",
    "    \"none|anti-heroic\": \"none|anti-hero\",\n",
    "    \"anti-hero\": \"anti-hero\",\n",
    "    \"none / anti-hero\": \"none|anti-hero\",\n",
    "    \"group\": \"group\",\n",
    "    \"heroic\": \"heroic\",\n",
    "    \"ordinary\": \"ordinary\"\n",
    "}\n",
    "\n",
    "# Apply label map to both sides\n",
    "def normalize_label(label):\n",
    "    if pd.isna(label):\n",
    "        return \"\"\n",
    "    label = label.lower().strip()\n",
    "    return label_map.get(label, label)\n",
    "\n",
    "# Normalize benchmark labels (which may have multiple correct ones)\n",
    "def normalize_set(label_str):\n",
    "    if pd.isna(label_str):\n",
    "        return set()\n",
    "    parts = [normalize_label(part) for part in label_str.split(\"|\")]\n",
    "    return set(parts)\n",
    "\n",
    "truth_df[\"hero_type_set\"] = truth_df[\"hero_type\"].apply(normalize_set)\n",
    "model_df[\"normalized_vote\"] = model_df[\"weighted_vote\"].apply(normalize_label)\n",
    "\n",
    "# === Merge and Evaluate ===\n",
    "merged_df = pd.merge(model_df, truth_df, on=\"subtitle_filename\", how=\"inner\")\n",
    "merged_df[\"is_correct\"] = merged_df.apply(\n",
    "    lambda row: row[\"normalized_vote\"] in row[\"hero_type_set\"], axis=1\n",
    ")\n",
    "\n",
    "# === Prepare Output CSV ===\n",
    "evaluation_df = merged_df[[\n",
    "    \"subtitle_filename\", \"hero_type\", \"normalized_vote\", \"is_correct\"\n",
    "]].copy()\n",
    "evaluation_df.columns = [\"movie\", \"benchmark_hero_type\", \"model_hero_type\", \"is_correct\"]\n",
    "evaluation_df.to_csv(output_path, index=False)\n",
    "\n",
    "# === Summary ===\n",
    "total = len(evaluation_df)\n",
    "correct = evaluation_df[\"is_correct\"].sum()\n",
    "accuracy = correct / total if total else 0\n",
    "\n",
    "print(f\"🎯 Evaluation complete:\")\n",
    "print(f\"✅ Correct: {correct}/{total}\")\n",
    "print(f\"📊 Accuracy: {accuracy:.2%}\")\n",
    "print(f\"📁 Saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbbcc51-7309-4f15-b0c6-9e83b8b43d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_clean_env_py310)",
   "language": "python",
   "name": "my_clean_env_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
